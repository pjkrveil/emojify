import numpy as np
from emo_utils import *
import emoji
import matplotlib.pyplot as plt


def sentence_to_avg(sentence, word_to_vec_map):
	"""
	Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word
	and averages its value into a single vector encoding the meaning of the sentence.

	Arguments:
	sentence -- string, one training example from X
	word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation

	Returns:
	avg -- average vector encoding information about the sentence, numpy-array of shape (50,)
	"""

	# Step 1: Split sentence into list of lower case words.
	words = sentence.lower().split()

	# Initialize the average word vector, should have the same shape as your word vectors.
	avg = np.zeros((50,))

	# Step 2: average the word vectors. You can loop over the words in the list "words".
	for w in words:
		avg += word_to_vec_map[w]
	avg = avg / len(words)

	return avg




if __name__ == '__main__':

# load the datase
# split the dataset between training (127 examples) and testing (56 examples).
X_train, Y_train = read_csv('data/train_emoji.csv')
X_test, Y_test = read_csv('data/tesss.csv')

maxLen = len(max(X_train, key=len).split())

index = 1
print(X_train[index], label_to_emoji(Y_train[index]))


# Convert Y from its current shape (m, 1) into a "one-hot representation" (m, 5),
# where each row is a one-hot vector giving the label of one example.

Y_oh_train = convert_to_one_hot(Y_train, C = 5)
Y_oh_test = convert_to_one_hot(Y_test, C = 5)

index = 50
print(Y_train[index], "is converted into one hot", Y_oh_train[index])


# load the word_to_vec_map, which contains all the vector representations.
word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('./data/glove.6B.50d.txt')

word = "cucumber"
index = 289846
print("the index of", word, "in the vocabulary is", word_to_index[word])
print("the", str(index) + "th word in the vocabulary is", index_to_word[index])


